{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Proprietary content. © Great Learning. All Rights Reserved. Unauthorized use or distribution prohibited."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "hirWJRX7qKqI"
   },
   "source": [
    "## Read PDF file with python"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "pHNNH6gOqNb4",
    "outputId": "22f502bc-15b3-4ff2-ba25-dc2520238446"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting PyPDF2\n",
      "  Downloading pypdf2-3.0.1-py3-none-any.whl.metadata (6.8 kB)\n",
      "Downloading pypdf2-3.0.1-py3-none-any.whl (232 kB)\n",
      "   ---------------------------------------- 0.0/232.6 kB ? eta -:--:--\n",
      "   - -------------------------------------- 10.2/232.6 kB ? eta -:--:--\n",
      "   ----- --------------------------------- 30.7/232.6 kB 435.7 kB/s eta 0:00:01\n",
      "   ---------- ---------------------------- 61.4/232.6 kB 544.7 kB/s eta 0:00:01\n",
      "   ----------------------- -------------- 143.4/232.6 kB 944.1 kB/s eta 0:00:01\n",
      "   -------------------------------------- - 225.3/232.6 kB 1.3 MB/s eta 0:00:01\n",
      "   ---------------------------------------- 232.6/232.6 kB 1.1 MB/s eta 0:00:00\n",
      "Installing collected packages: PyPDF2\n",
      "Successfully installed PyPDF2-3.0.1\n"
     ]
    }
   ],
   "source": [
    "!pip install PyPDF2\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "qWC1DRjKqS7s",
    "outputId": "74f3f0b4-2876-4559-fd1d-148612a617b8"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "41\n"
     ]
    }
   ],
   "source": [
    "# importing required modules \n",
    "import PyPDF2 \n",
    "\n",
    "# creating a pdf file object \n",
    "data = open('Introduction+to+natural+language+processing.pdf', 'rb') \n",
    "\n",
    "# creating a pdf reader object \n",
    "reader = PyPDF2.PdfReader(data) \n",
    "\n",
    "# printing number of pages in pdf file \n",
    "print(len(reader.pages) )\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "id": "OjjcNckVq5GD"
   },
   "outputs": [],
   "source": [
    "# creating a page object \n",
    "page=  reader.pages[1] \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "xmrD80d1q-Nh",
    "outputId": "c93560a8-b84d-4e2e-8594-6da0d02edc0a"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Agenda\n",
      "Proprietary content. ©Great Learning. All Rights Reserved. Unauthorized use or distribution prohibited● What is Natural language processing ?\n",
      "● Examples of Natural language processing\n",
      "● Roadmap to learn natural language processing\n",
      "● What is python?\n",
      "○Importance of Python\n",
      "○Important libraries in Python\n",
      "● What is data?\n",
      "● What is data pre -processing?\n",
      "● Types of data pre -processing\n",
      "○What is tokenization?\n",
      "○What is stemming?\n",
      "○What is lemmatization?○What are stop words?\n",
      "● Modelling techniques\n",
      "○What is bag of words?\n",
      "○What is TF -IDF?\n",
      "○What is word embedding?\n",
      "○What is sentiment analysis?\n",
      "● Project on sentiment analysis\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# extracting text from page \n",
    "print(page.extract_text()) \n",
    "\n",
    "# closing the pdf file object \n",
    "data.close() "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "iFwak8iArHeQ"
   },
   "source": [
    "## Working with text file in Python"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "6GKywv3trLPM",
    "outputId": "3ec20171-032f-4d74-b65a-bca130cce6a6"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Welcome to NLP!!!!!!!!!!!!!\n"
     ]
    }
   ],
   "source": [
    "text_data= open(\"demo_file.txt\", \"r\")\n",
    "print(text_data.read())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "BXe11qXBrrzx"
   },
   "source": [
    "## Working with CSV file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "id": "bvJYp7g7tXhi"
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "id": "DQgpaxkFusT8"
   },
   "outputs": [],
   "source": [
    "data=pd.read_csv(\"country.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 204
    },
    "id": "c1B1OG43x6Ia",
    "outputId": "ebc9507f-0c97-439b-8861-c5688df818ea"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Name</th>\n",
       "      <th>Code</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Afghanistan</td>\n",
       "      <td>AF</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Åland Islands</td>\n",
       "      <td>AX</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Albania</td>\n",
       "      <td>AL</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Algeria</td>\n",
       "      <td>DZ</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>American Samoa</td>\n",
       "      <td>AS</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "             Name Code\n",
       "0     Afghanistan   AF\n",
       "1   Åland Islands   AX\n",
       "2         Albania   AL\n",
       "3         Algeria   DZ\n",
       "4  American Samoa   AS"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "rCfL8CZPrvOP",
    "outputId": "23e1a232-3e10-425b-be82-5fe3a33af6fc"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['Name', 'Code'], dtype='object')"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "bhYTxz-Trw0W",
    "outputId": "e10d0acd-83c7-44c4-bf64-6c957e1440ca"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(249, 2)"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 297
    },
    "id": "PJx49Pk5rydB",
    "outputId": "b46d1977-1c63-4d5c-979d-c0128d07843e"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Name</th>\n",
       "      <th>Code</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>249</td>\n",
       "      <td>248</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>unique</th>\n",
       "      <td>249</td>\n",
       "      <td>248</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>top</th>\n",
       "      <td>Afghanistan</td>\n",
       "      <td>AF</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>freq</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "               Name Code\n",
       "count           249  248\n",
       "unique          249  248\n",
       "top     Afghanistan   AF\n",
       "freq              1    1"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "W6e9nrRIr0qw",
    "outputId": "683bf41a-0745-4158-f112-1276ef1ba481"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Name    0\n",
       "Code    1\n",
       "dtype: int64"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "2tkeSfvbr5ys",
    "outputId": "28824955-015e-43c1-f918-32280898bdb9"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Name    False\n",
       "Code     True\n",
       "dtype: bool"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.isnull().any()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "id": "h_9X5Pn_r-t1"
   },
   "outputs": [],
   "source": [
    "data_part=data.dropna()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 419
    },
    "id": "o2veumzssUe-",
    "outputId": "fb60dbec-0128-44b9-e541-cd4dd728e1c6"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Name</th>\n",
       "      <th>Code</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Afghanistan</td>\n",
       "      <td>AF</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Åland Islands</td>\n",
       "      <td>AX</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Albania</td>\n",
       "      <td>AL</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Algeria</td>\n",
       "      <td>DZ</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>American Samoa</td>\n",
       "      <td>AS</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>244</th>\n",
       "      <td>Wallis and Futuna</td>\n",
       "      <td>WF</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>245</th>\n",
       "      <td>Western Sahara</td>\n",
       "      <td>EH</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>246</th>\n",
       "      <td>Yemen</td>\n",
       "      <td>YE</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>247</th>\n",
       "      <td>Zambia</td>\n",
       "      <td>ZM</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>248</th>\n",
       "      <td>Zimbabwe</td>\n",
       "      <td>ZW</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>248 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                  Name Code\n",
       "0          Afghanistan   AF\n",
       "1        Åland Islands   AX\n",
       "2              Albania   AL\n",
       "3              Algeria   DZ\n",
       "4       American Samoa   AS\n",
       "..                 ...  ...\n",
       "244  Wallis and Futuna   WF\n",
       "245     Western Sahara   EH\n",
       "246              Yemen   YE\n",
       "247             Zambia   ZM\n",
       "248           Zimbabwe   ZW\n",
       "\n",
       "[248 rows x 2 columns]"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_part"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "MYrAhAtGsVzh",
    "outputId": "99d42d15-c5c3-4135-8cfc-97b7c593867b"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(248, 2)"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_part.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "cxUgjr3Dx_O-"
   },
   "source": [
    "## Line tokenization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "zhZLxffasX5K",
    "outputId": "15c5ba6e-5e76-494c-bc00-ce5837fd80c5"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Welcome to Great Learning!', '!']\n"
     ]
    }
   ],
   "source": [
    "import nltk\n",
    "data = \"Welcome to Great Learning!! \"\n",
    "tokens = nltk.sent_tokenize(data)\n",
    "print (tokens)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "0hzGl1QjyClA"
   },
   "source": [
    "## Word tokenization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "qxJ5sbbUxECn",
    "outputId": "6c796862-cf0a-42b6-bd0b-c95e791ae354"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Welcome', 'to', 'Great', 'Learning', '!', '!']\n"
     ]
    }
   ],
   "source": [
    "tokens = nltk.word_tokenize(data)\n",
    "print (tokens)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "DV-CwHe4ypiQ"
   },
   "source": [
    "## Stemming"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "1a8AwRDIyOav",
    "outputId": "ea2a7823-c7c6-4536-98ee-5ac5931b819b"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Like  :  like\n",
      "Liking  :  like\n",
      "Likes  :  like\n"
     ]
    }
   ],
   "source": [
    "# import these modules \n",
    "from nltk.stem import PorterStemmer \n",
    "\n",
    "ps = PorterStemmer() \n",
    "\n",
    "# choose some words to be stemmed \n",
    "words = [\"Like\",\"Liking\",\"Likes\"] \n",
    "\n",
    "for i in words: \n",
    "\tprint(i, \" : \", ps.stem(i)) \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "3XU-mee5zK07"
   },
   "source": [
    "## Lemmatization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "JIifxZskzPZS",
    "outputId": "0a9f1415-78e1-41dd-ba5d-6c7591bc76ee"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package wordnet to\n",
      "[nltk_data]     C:\\Users\\Anusha\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package wordnet is already up-to-date!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import nltk\n",
    "nltk.download('wordnet')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "FGOuSuxNyzDY",
    "outputId": "7c10749c-4a60-4e1c-c998-dbc1d6635700"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "socks: sock\n",
      "sons: son\n"
     ]
    }
   ],
   "source": [
    "# import these modules \n",
    "from nltk.stem import WordNetLemmatizer \n",
    "\n",
    "lemmati = WordNetLemmatizer() \n",
    "\n",
    "print(\"socks:\", lemmati.lemmatize(\"socks\")) \n",
    "print(\"sons:\", lemmati.lemmatize(\"sons\")) \n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "6rFlCwwi0GIk"
   },
   "source": [
    "## Removing stop words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "o5-kXnwzzHD6",
    "outputId": "e432061f-6c9e-45ba-f773-a4663cb2db42"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'at', 'being', 'doesn', 'm', \"mightn't\", 'in', 'up', 'more', 'than', 'out', 'did', 'that', 'of', \"weren't\", 'don', 'hasn', 'who', 'how', 'any', 'needn', 'and', 'again', 'him', 'couldn', 'we', 'themselves', 'her', 'where', 'these', 'the', 'on', 'both', 't', \"mustn't\", \"you're\", 'against', 'too', 'under', \"didn't\", 'while', 'this', 'between', 'same', 'ourselves', 'isn', 's', 'most', 'aren', 'you', 'if', 'were', 'didn', 'an', 'does', 'had', 'all', 'ain', 'itself', 'which', 'will', \"don't\", 'i', 'yourself', 'such', 'whom', 'am', 'haven', \"doesn't\", 'herself', 'below', 'by', 'to', \"you've\", \"should've\", 'what', \"shan't\", \"wasn't\", 'off', 'yourselves', 'do', 'there', 'are', 'has', 'now', 'hadn', 'me', 'it', 'some', 'be', 'ma', 'very', 'when', \"that'll\", 'each', \"it's\", 'should', 'she', 'have', \"you'll\", 'during', 'wouldn', 'only', 'their', 'himself', 'once', \"hadn't\", 'his', 'ours', 'them', 'so', \"won't\", \"needn't\", 'then', 'few', 'won', 'above', 'further', \"she's\", 'those', 'weren', \"you'd\", 'yours', 'as', 'from', 'myself', 'our', 'is', 'he', 'not', 'until', 'shan', 'your', 'here', \"aren't\", 'into', 'd', 'a', 'for', 'with', 'll', 'other', \"isn't\", 'o', 'theirs', 'was', 'mightn', 'but', 're', 'or', 'down', 'nor', \"haven't\", 'no', 've', 'my', 'y', 'after', 'can', 'own', 'its', 'why', 'they', 'about', 'through', 'before', 'hers', \"shouldn't\", \"wouldn't\", 'wasn', 'having', 'doing', 'because', \"hasn't\", 'been', 'just', \"couldn't\", 'mustn', 'shouldn', 'over'}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     C:\\Users\\Anusha\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "from nltk.corpus import stopwords \n",
    "import nltk\n",
    "nltk.download('stopwords')\n",
    "\n",
    "\n",
    "new_data = \"\"\"Data science is one of the most trendind field to work with. It needs data to give prediction by using the past scenarios\"\"\"\n",
    "\n",
    "stop_word = set(stopwords.words('english')) \n",
    "\n",
    "#print(stopwords.words() [620:680])\n",
    "\n",
    "print(stop_word)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {
    "id": "riWuQgpu0VmN"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Data', 'science', 'is', 'one', 'of', 'the', 'most', 'trendind', 'field', 'to', 'work', 'with', '.', 'It', 'needs', 'data', 'to', 'give', 'prediction', 'by', 'using', 'the', 'past', 'scenarios']\n"
     ]
    }
   ],
   "source": [
    "new_data= nltk.word_tokenize(new_data)\n",
    "print(new_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {
    "id": "gGuRxvTL1Jw2"
   },
   "outputs": [],
   "source": [
    "stops = set(stopwords.words('english'))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "-qPgOusb1Odd",
    "outputId": "b8ea4cf7-db94-42b3-9e74-e13e9e9518d7"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data\n",
      "science\n",
      "one\n",
      "trendind\n",
      "field\n",
      "work\n",
      ".\n",
      "It\n",
      "needs\n",
      "data\n",
      "give\n",
      "prediction\n",
      "using\n",
      "past\n",
      "scenarios\n"
     ]
    }
   ],
   "source": [
    "for word in new_data: \n",
    "    if word not in stops:\n",
    "        print(word)"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [],
   "name": "demo_of_nlp.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
